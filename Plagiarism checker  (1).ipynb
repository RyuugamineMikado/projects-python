{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d24d59",
   "metadata": {},
   "source": [
    "## Plagiarism-Checker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d322ed2",
   "metadata": {},
   "source": [
    "Using python I have created a plagiarism checker that simply tests the similarity between all combinations of .txt files. It uses Vectorizer to set a numerical value to all files based on the words used, and compares it with cosine similarity (based on cosine law). In other words, the file gets turned into a vector, and the cosine similarity reads the angle between the two vectors and lists that as the % similarity. This program will try all combinations of files and print them out at the end.\n",
    "\n",
    "The Euclidean distance (or cosine similarity) between two word vectors provides an effective method for measuring the linguistic or semantic similarity of the corresponding words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d952fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51d94b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_be_checked = [doc for doc in os.listdir() if doc.endswith('.txt')]\n",
    "notes =[open(file).read() for file in  files_to_be_checked]\n",
    "vectorize = lambda Text: TfidfVectorizer().fit_transform(Text).toarray()\n",
    "similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2])\n",
    "vectors = vectorize(notes)\n",
    "s_vectors = list(zip(files_to_be_checked, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ef59098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plagiarism_check():\n",
    "    plagiarism_results = set()\n",
    "    global s_vectors\n",
    "    for student_1, text_vector_1 in s_vectors:\n",
    "        new_vectors =s_vectors.copy()\n",
    "        current_index = new_vectors.index((student_1, text_vector_1))\n",
    "        del new_vectors[current_index]\n",
    "        for student_2 , text_vector_2 in new_vectors:\n",
    "            sim_score = similarity(text_vector_1, text_vector_2)[0][1]\n",
    "            student_pair = sorted((student_1, student_2))\n",
    "            score = (student_pair[0], student_pair[1],sim_score)\n",
    "            plagiarism_results.add(score)\n",
    "    return plagiarism_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd63f82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test1.txt', 'test2.txt', 0.14806887549598563)\n",
      "('test1.txt', 'test3.txt', 0.18643448370323357)\n",
      "('test2.txt', 'test3.txt', 0.5465972177348937)\n"
     ]
    }
   ],
   "source": [
    "for data in check_plagiarism():\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
